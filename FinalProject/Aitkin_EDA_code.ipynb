{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mta_data']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "%config InlineBackend.figure_formats = ['svg']  # or retina\n",
    "%matplotlib inline\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "\n",
    "sns.set(context='notebook', \n",
    "    style='whitegrid', \n",
    "    font_scale=1.1)\n",
    "\n",
    "# use python get_mta.py \"(2104|2105|2106|2107|2108|2109)\" in Terminal\n",
    "\n",
    "engine = create_engine(\"sqlite:///mta_data.db\")\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM mta_data WHERE DESC = \"REGULAR\";', engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a \"key\" so don't have to keep typing all the column names\n",
    "df['key']=df['SCP']+df['UNIT']+df['C/A']+df['STATION']+df['LINENAME']\n",
    "\n",
    "#create a datetime object out of date and time so they aren't strings\n",
    "df[\"DATE_TIME\"] = pd.to_datetime(df.DATE + \" \" + df.TIME, \n",
    "                                format=\"%m/%d/%Y %H:%M:%S\")\n",
    "#sort everything by turnstile and by date so can subtract the right things\n",
    "df.sort_values(['key','DATE_TIME'],ascending=True,inplace = True, ignore_index = True)\n",
    "\n",
    "#from https://github.com/rjh336/mta_metis/blob/master/benson_cleaner.ipynb\n",
    "#create a column with just the hours so can find the hours we're intersted in. \n",
    "df[\"just_time\"]  = df['DATE_TIME'].apply(lambda x: x.time())\n",
    "#create a day of the week so can delete Saturdays and Sundays\n",
    "df['DOW'] = df[['DATE_TIME']]\\\n",
    "    .apply(lambda x: datetime.datetime.strftime(x['DATE_TIME'], '%A'), axis=1)\n",
    "\n",
    "\n",
    "#create the differences in the entries from the last reading. restarts each day\n",
    "#from https://stackoverflow.com/questions/20648346/computing-diffs-within-groups-of-a-dataframe\n",
    "df['entries_diffs'] = df.groupby(['key','DATE'])['ENTRIES'].transform(lambda x: x.diff()) \n",
    "#create the differences in the exits from the last reading. restarts each day\n",
    "df['exits_diffs'] = df.groupby(['key','DATE'])['EXITS'].transform(lambda x: x.diff()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframes so the old one still exists\n",
    "# drop apparently unnecessary columns or rows in each change. \n",
    "# Note: columns/rows are still in old data frames\n",
    "# need to keep DATE because using to find duplicates much later\n",
    "# need to keep LINENAME because multiple STATIONS with same name\n",
    "df2 = df.drop(['DIVISION','TIME','DESC'],axis = 1).copy()\n",
    "mask = ((df2.DOW != 'Saturday') & (df2.DOW != 'Sunday'))\n",
    "df3 = df2[mask].copy()\n",
    "df3 = df3.drop(['ENTRIES','EXITS'],axis = 1).copy()\n",
    "\n",
    "# sorting by key and DATE_TIME show large outliers\n",
    "# this code drops outliers - anything bigger than number of seconds in a day\n",
    "# from https://github.com/rjh336/mta_metis/blob/master/benson_cleaner.ipynb\n",
    "threshold = 86400 #number of seconds in the day\n",
    "\n",
    "## DROP OUTLIERS\n",
    "df3 = df3[(df3['entries_diffs'] < threshold) & (df3['exits_diffs'] < threshold)]\n",
    "df3 = df3[(df3['entries_diffs'] > -threshold) & (df3['exits_diffs'] > -threshold)]\n",
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_neg_counts(row,keycol):\n",
    "    '''\n",
    "    from MTA pair 2. converts negative numbers to positive ones\n",
    "    Exploration showed some of the cumulative counts were backwards, so getting \n",
    "    the difference created negative numbers; \n",
    "    they should just be converted to positive\n",
    "    '''\n",
    "\n",
    "    counter = row[keycol]\n",
    "    if counter < 0:\n",
    "        counter = -counter  \n",
    "    return counter\n",
    "\n",
    "\n",
    "df4['exits_diffs'] = df4.apply(convert_neg_counts, axis=1,keycol= 'exits_diffs')\n",
    "df4['entries_diffs'] = df4.apply(convert_neg_counts, axis=1,keycol= 'entries_diffs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#am rush hour dataframe\n",
    "mask = ((df4.just_time >= datetime.time(8)) & (df4.just_time <= datetime.time(9, 30)))\n",
    "df_am = df4[mask].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST ROUND. AM ENTRIES\n",
    "#group by station and sum for the few cases\n",
    "# where there are multiple readings in the time range for that date/station\n",
    "station_am_entry = df_am.groupby([\"STATION\",\"LINENAME\", \"DATE\"])[['entries_diffs']].sum().reset_index()\n",
    "\n",
    "# am entries. Across all days for that station, so take mean\n",
    "station_am_all_entry = station_am_entry.groupby([\"STATION\",'LINENAME'])[['entries_diffs']].mean().reset_index() \\\n",
    "    .sort_values('entries_diffs',ascending=False)\n",
    "\n",
    "\n",
    "# first graph\n",
    "plt.bar(x=station_am_all_entry['STATION'][:20], height=station_am_all_entry['entries_diffs'][:20])\n",
    "plt.xticks(rotation=90, fontsize = 10);\n",
    "plt.ylabel(\"Average Morning Weekday Entries\");\n",
    "plt.title('Top 20 Average Morning Weekday Entries Between April 3 and September 11')\n",
    "plt.savefig('allAM_6mo.png',dpi = 600,bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check an outlier in the bar chart\n",
    "station_daily = station_am_entry[station_am_entry['STATION'] == 'JOURNAL SQUARE'].copy()\n",
    "\n",
    "station_daily['DAY_OF_WEEK_NUM'] = pd.to_datetime(station_daily['DATE']).dt.dayofweek\n",
    "station_daily['WEEK_OF_YEAR'] = pd.to_datetime(station_daily['DATE']).dt.isocalendar().week\n",
    "for i, group in station_daily.groupby('WEEK_OF_YEAR'):\n",
    "    plt.plot(group['DAY_OF_WEEK_NUM'], group['entries_diffs'])\n",
    "station_daily.head() \n",
    "station_daily.shape\n",
    "plt.xlabel('Day of the week')\n",
    "plt.ylabel('Number of turnstile entries')\n",
    "plt.xticks(np.arange(5),['Mo','Tu','We','Th','Fr'])\n",
    "plt.title('Morning Entries per day for 42 St - Port Authority station');\n",
    "plt.savefig('PortAuth_6Mo.png',dpi = 600,bbox_inches = 'tight');\n",
    "#note there are only 5 days out of 6 full months that have high numbers. \n",
    "#Mean is probably an outlier. Use graph to demonstrate why don't use Journal Square\n",
    "# can reuse this code and change station name to check for other outliers;\n",
    "# will not include the code everytime its used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask for evening rush hours: 5 pm to 8 pm. 8 pm because that's when most of \n",
    "# the data is collected\n",
    "mask = ((df4.just_time >= datetime.time(17)) & (df4.just_time <= datetime.time(20)))\n",
    "df_pm = df4[mask].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECOND ROUND. EVENING EXITS\n",
    "#group by station and sum for the few cases\n",
    "# where there are multiple readings in the time range\n",
    "station_pm_exit = df_pm.groupby([\"STATION\",'LINENAME', \"DATE\"])[['exits_diffs']].sum().reset_index()\n",
    "#across all days per station so take mean\n",
    "station_pm_all_exit = station_pm_exit.groupby([\"STATION\",'LINENAME'])[['exits_diffs']].mean().reset_index() \\\n",
    "    .sort_values('exits_diffs',ascending=False)\n",
    "\n",
    "#graph 2\n",
    "plt.bar(x=station_pm_all_exit['STATION'][:20], height=station_pm_all_exit['exits_diffs'][:20])\n",
    "plt.xticks(rotation=90, fontsize = 10);\n",
    "plt.ylabel(\"Average Evening Weekday Exits\");\n",
    "plt.title('Top 20 Average Evening Weekday Exits from April to September 2021')\n",
    "plt.savefig('allPMexits_6Mo.png',dpi = 600,bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIRD ROUND. MORNING EXITS\n",
    "#sum for few cases where multiple readings - see above\n",
    "station_am_exits = df_am.groupby([\"STATION\",\"LINENAME\", \"DATE\"])[['exits_diffs']].sum().reset_index()\n",
    "# take mean because averaging across days\n",
    "station_am_all_exit = station_am_exits.groupby([\"STATION\",'LINENAME'])[['exits_diffs']].mean().reset_index() \\\n",
    "    .sort_values('exits_diffs',ascending=False)\n",
    "\n",
    "## make sure all the dataframes and the labels are correct!!\n",
    "plt.bar(x=station_am_all_exit['STATION'][:20], height=station_am_all_exit['exits_diffs'][:20])\n",
    "plt.xticks(rotation=90, fontsize = 10);\n",
    "plt.ylabel(\"Average Morning Weekday Exits\");\n",
    "plt.title('Top 20 Average Morning Weekday Exits from April to September 2021')\n",
    "plt.savefig('allAMexits_6MO.png',dpi = 600,bbox_inches = 'tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOURTH ROUND. EVENING ENTRIES\n",
    "# weird name to confirm using correct dataframe\n",
    "#sum in case of multiple entries on a day/station/linename combo\n",
    "station_pm_eentries = df_pm.groupby([\"STATION\",\"LINENAME\", \"DATE\"])[['entries_diffs']].sum().reset_index()\n",
    "#mean across all days\n",
    "station_pm_all_eentry = station_pm_eentries.groupby([\"STATION\",'LINENAME'])[['entries_diffs']].mean().reset_index() \\\n",
    "    .sort_values('entries_diffs',ascending=False)\n",
    "station_pm_all_eentry.head()\n",
    "# make sure dataframes and labels are correct!!\n",
    "plt.bar(x=station_pm_all_eentry['STATION'][:20], height=station_pm_all_eentry['entries_diffs'][:20])\n",
    "plt.xticks(rotation=90, fontsize = 10);\n",
    "plt.ylabel(\"Average Evening Weekday Entries\");\n",
    "plt.title('Top 20 Average Evening Weekday Entries over April to September 2021')\n",
    "plt.savefig('allPMentries_6MO.png',dpi = 600,bbox_inches = 'tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the noon exits to see if more accurate than 8-9:30\n",
    "mask = ((df4.just_time >= datetime.time(11, 30)) & (df4.just_time <= datetime.time(12)))\n",
    "df_noon = df4[mask].copy()\n",
    "\n",
    "station_noon_exit = df_noon.groupby(['key',\"STATION\", \"DATE\"])[['exits_diffs']].sum().reset_index()\n",
    "\n",
    "station_noon_all_exits = station_noon_exit.groupby([\"STATION\"])[['exits_diffs']].mean().reset_index() \\\n",
    "    .sort_values('exits_diffs',ascending=False)\n",
    "plt.bar(x=station_noon_all_exits['STATION'][:20], height=station_noon_all_exits['exits_diffs'][:20])\n",
    "plt.xticks(rotation=90, fontsize = 10);\n",
    "plt.ylabel(\"Average All Through Noon Weekday Exits\", fontsize = 12);\n",
    "plt.title('Top 20 Average Morning Through Noon Weekday Exits from April to September 2021')\n",
    "plt.savefig('allnoon_exits.png',dpi = 600,bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The morning entries probably most accurate. Make a pretty graph of them\n",
    "mm = sns.barplot(x=station_am_all_entry['STATION'][:20], y=station_am_all_entry['entries_diffs'][:20],ci = None)\n",
    "mm.set_xticklabels(mm.get_xticklabels(), \n",
    "                          rotation=90);\n",
    "mm.set(xlabel = '',ylabel='Average AM Entries');\n",
    "mm.set(title = 'Average Morning Entries From April to September, 2021');\n",
    "plt.savefig('rainbowAMentries.png',dpi = 600,bbox_inches = 'tight');\n",
    "\n",
    "\n",
    "# Make a pretty graph of the morning exits as well\n",
    "nn = sns.barplot(x=station_am_all_exit['STATION'][:20], y=station_am_all_exit['exits_diffs'][:20], ci = None)\n",
    "nn.set_xticklabels(nn.get_xticklabels(), \n",
    "                          rotation=90);\n",
    "nn.set(xlabel = '',ylabel='Average AM Exits');\n",
    "nn.set(title = 'Average Morning Exits From April to September, 2021');\n",
    "plt.savefig('rainbowAMexits.png',dpi = 600,bbox_inches = 'tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the top 20 entries and exits in the four groups and find best ones\n",
    "aa= station_am_all_entry[['STATION','entries_diffs']][:20] # AM ENTRY\n",
    "bb= station_am_all_exit[['STATION','exits_diffs']][:20]    # AM EXIT\n",
    "cc=station_pm_all_eentry[['STATION','entries_diffs']][:20] # PM ENTRY\n",
    "dd = station_pm_all_exit[['STATION','exits_diffs']][:20]   # PM EXIT\n",
    "\n",
    "# rename the columns so can combine all four arrays\n",
    "aa.rename(columns = {'entries_diffs':'diffs'}, inplace = True)\n",
    "bb.rename(columns = {'exits_diffs':'diffs'}, inplace = True) \n",
    "cc.rename(columns = {'entries_diffs':'diffs'}, inplace = True)\n",
    "dd.rename(columns = {'exits_diffs':'diffs'}, inplace = True)\n",
    "ee=np.concatenate((aa,bb,cc,dd))\n",
    "# same as DataFrame so easy to sort\n",
    "ff = pd.DataFrame(ee)\n",
    "ff.sort_values(1,ascending= False,inplace = True)\n",
    "# drop duplicates\n",
    "ff.drop_duplicates(0)\n",
    "# print out and copy to PowerPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
